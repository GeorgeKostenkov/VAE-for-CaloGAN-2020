{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_Kostenkov.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtK0X7GchvEn",
        "colab_type": "code",
        "outputId": "38a99213-2706-48bb-8b5d-56d05acd13e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! wget https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/calogan_metrics.py\n",
        "! wget https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/prd_score.py\n",
        "! wget https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/score.py\n",
        "! wget https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/embedder.tp\n",
        "! wget https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/generator.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "sns.set()\n",
        "\n",
        "def one_hot(a, num_classes):\n",
        "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-11 16:35:43--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/calogan_metrics.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4115 (4.0K) [text/plain]\n",
            "Saving to: ‘calogan_metrics.py.1’\n",
            "\n",
            "\rcalogan_metrics.py.   0%[                    ]       0  --.-KB/s               \rcalogan_metrics.py. 100%[===================>]   4.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-11 16:35:43 (103 MB/s) - ‘calogan_metrics.py.1’ saved [4115/4115]\n",
            "\n",
            "--2020-02-11 16:35:44--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/prd_score.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12426 (12K) [text/plain]\n",
            "Saving to: ‘prd_score.py.1’\n",
            "\n",
            "prd_score.py.1      100%[===================>]  12.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-11 16:35:44 (232 MB/s) - ‘prd_score.py.1’ saved [12426/12426]\n",
            "\n",
            "--2020-02-11 16:35:45--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/score.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7642 (7.5K) [text/plain]\n",
            "Saving to: ‘score.py.1’\n",
            "\n",
            "score.py.1          100%[===================>]   7.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-11 16:35:45 (112 MB/s) - ‘score.py.1’ saved [7642/7642]\n",
            "\n",
            "--2020-02-11 16:35:46--  https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/embedder.tp\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/embedder.tp [following]\n",
            "--2020-02-11 16:35:47--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/embedder.tp\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 569697 (556K) [application/octet-stream]\n",
            "Saving to: ‘embedder.tp.1’\n",
            "\n",
            "embedder.tp.1       100%[===================>] 556.34K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-02-11 16:35:47 (15.2 MB/s) - ‘embedder.tp.1’ saved [569697/569697]\n",
            "\n",
            "--2020-02-11 16:35:48--  https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/generator.py\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/generator.py [following]\n",
            "--2020-02-11 16:35:48--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/generator.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1514 (1.5K) [text/plain]\n",
            "Saving to: ‘generator.py.1’\n",
            "\n",
            "generator.py.1      100%[===================>]   1.48K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-11 16:35:48 (284 MB/s) - ‘generator.py.1’ saved [1514/1514]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKd7ysSIiHOJ",
        "colab_type": "code",
        "outputId": "2daba811-d6e2-48e9-9001-75e2a195061b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mbPg_QAiKNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_path = '/gdrive/My Drive/mlhep2019_gan/data_train.npz'\n",
        "val_data_path = '/gdrive/My Drive/mlhep2019_gan/data_val.npz'\n",
        "test_data_path = '/gdrive/My Drive/mlhep2019_gan/data_test.npz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-h15641icfy",
        "colab_type": "code",
        "outputId": "641aafdf-434a-4fb5-e876-b4f33588aa4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "N = 1000\n",
        "\n",
        "data_train = np.load(train_data_path, allow_pickle=True)\n",
        "print(list(data_train.keys()))\n",
        "\n",
        "# [data_size, 900]\n",
        "EnergyDeposit = data_train['EnergyDeposit'][:N]\n",
        "# reshaping it as [data_size, channels, img_size_x, img_size_y]\n",
        "# channels are needed for pytorch conv2d-layers\n",
        "EnergyDeposit = EnergyDeposit.reshape(-1, 1, 30, 30)\n",
        "\n",
        "# [data_size, 3]\n",
        "ParticleMomentum = data_train['ParticleMomentum'][:N]\n",
        "\n",
        "# [data_size, 2]\n",
        "ParticlePoint = data_train['ParticlePoint'][:, :2][:N]\n",
        "\n",
        "# [data_size, 1]\n",
        "ParticlePDG = data_train['ParticlePDG'][:N]"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['EnergyDeposit', 'ParticlePoint', 'ParticleMomentum', 'ParticlePDG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvSWl8hxifza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit = torch.tensor(EnergyDeposit).float()\n",
        "ParticleMomentum = torch.tensor(ParticleMomentum).float()\n",
        "ParticlePoint = torch.tensor(ParticlePoint).float()\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "calo_dataset = utils.TensorDataset(EnergyDeposit, ParticleMomentum, ParticlePoint)\n",
        "calo_dataloader = torch.utils.data.DataLoader(calo_dataset, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoqqvcJWj_Cy",
        "colab_type": "code",
        "outputId": "63e79447-0942-4741-9bb3-c47ee0ed88ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "EnergyDeposit.shape"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 1, 30, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYROtHwZ5Pww",
        "colab_type": "code",
        "outputId": "ea161546-d6c7-4217-d227-a4b405c81114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b in calo_dataloader:\n",
        "            EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b = EnergyDeposit_b.to(device), \\\n",
        "                                                                   ParticleMomentum_b.to(device), \\\n",
        "                                                                   ParticlePoint_b.to(device)\n",
        "            ParticleMomentum_ParticlePoint_b = torch.cat([ParticleMomentum_b.to(device), ParticlePoint_b.to(device)], dim=1)\n",
        "            EnergyDeposit_b = EnergyDeposit_b.view(len(EnergyDeposit_b), -1)\n",
        "            data = torch.cat([EnergyDeposit_b, ParticleMomentum_ParticlePoint_b], dim=1)\n",
        "          #for batch_idx, (data, _) in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            loss = loss_function(recon_batch, data, mu, logvar)\n",
        "            loss.backward()\n",
        "            train_loss += loss.item()\n",
        "            optimizer.step()\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(calo_dataloader.dataset)))\n",
        "\n",
        "'''\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
        "'''"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef test(epoch):\\n    model.eval()\\n    test_loss = 0\\n    with torch.no_grad():\\n        for i, (data, _) in enumerate(test_loader):\\n            data = data.to(device)\\n            recon_batch, mu, logvar = model(data)\\n            test_loss += loss_function(recon_batch, data, mu, logvar).item()\\n\\n    test_loss /= len(test_loader.dataset)\\n    print('====> Test set loss: {:.4f}'.format(test_loss))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZZcrFLRkH5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(905, 500)\n",
        "        self.fc21 = nn.Linear(500, 30)\n",
        "        self.fc22 = nn.Linear(500, 30)\n",
        "        self.fc3 = nn.Linear(30, 500)\n",
        "        self.fc4 = nn.Linear(500, 905)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc21(h1), self.fc22(h1)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, 905))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "\n",
        "model = VAE().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "\n",
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    RMSE = torch.sqrt(torch.nn.functional.mse_loss(recon_x, x.view(-1, 905), reduction='sum'))\n",
        "\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return RMSE + KLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuEWkiS28uB9",
        "colab_type": "code",
        "outputId": "b7335a21-19ef-4627-fcee-1600415d0d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(1, 700):\n",
        "        train(epoch)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Average loss: 54810298223160008.0000\n",
            "====> Epoch: 2 Average loss: 2639.1718\n",
            "====> Epoch: 3 Average loss: 537.3898\n",
            "====> Epoch: 4 Average loss: 523.0493\n",
            "====> Epoch: 5 Average loss: 551.4626\n",
            "====> Epoch: 6 Average loss: 1099.7058\n",
            "====> Epoch: 7 Average loss: 519.9940\n",
            "====> Epoch: 8 Average loss: 501.7001\n",
            "====> Epoch: 9 Average loss: 717.0695\n",
            "====> Epoch: 10 Average loss: 500.1561\n",
            "====> Epoch: 11 Average loss: 493.6598\n",
            "====> Epoch: 12 Average loss: 42090.5484\n",
            "====> Epoch: 13 Average loss: 482.6287\n",
            "====> Epoch: 14 Average loss: 485.3702\n",
            "====> Epoch: 15 Average loss: 480.1142\n",
            "====> Epoch: 16 Average loss: 471.1477\n",
            "====> Epoch: 17 Average loss: 462.7370\n",
            "====> Epoch: 18 Average loss: 456.4029\n",
            "====> Epoch: 19 Average loss: 448.1143\n",
            "====> Epoch: 20 Average loss: 443.5032\n",
            "====> Epoch: 21 Average loss: 438.3045\n",
            "====> Epoch: 22 Average loss: 430.6312\n",
            "====> Epoch: 23 Average loss: 424.3483\n",
            "====> Epoch: 24 Average loss: 417.2792\n",
            "====> Epoch: 25 Average loss: 414.3236\n",
            "====> Epoch: 26 Average loss: 405.8132\n",
            "====> Epoch: 27 Average loss: 401.5725\n",
            "====> Epoch: 28 Average loss: 396.6010\n",
            "====> Epoch: 29 Average loss: 397.0536\n",
            "====> Epoch: 30 Average loss: 399.0978\n",
            "====> Epoch: 31 Average loss: 402.8534\n",
            "====> Epoch: 32 Average loss: 402.2070\n",
            "====> Epoch: 33 Average loss: 396.8520\n",
            "====> Epoch: 34 Average loss: 391.4690\n",
            "====> Epoch: 35 Average loss: 387.2073\n",
            "====> Epoch: 36 Average loss: 382.6509\n",
            "====> Epoch: 37 Average loss: 377.8061\n",
            "====> Epoch: 38 Average loss: 372.9372\n",
            "====> Epoch: 39 Average loss: 370.3954\n",
            "====> Epoch: 40 Average loss: 365.7895\n",
            "====> Epoch: 41 Average loss: 362.8657\n",
            "====> Epoch: 42 Average loss: 359.3331\n",
            "====> Epoch: 43 Average loss: 355.5674\n",
            "====> Epoch: 44 Average loss: 352.2192\n",
            "====> Epoch: 45 Average loss: 348.7435\n",
            "====> Epoch: 46 Average loss: 345.2704\n",
            "====> Epoch: 47 Average loss: 341.7202\n",
            "====> Epoch: 48 Average loss: 339.6863\n",
            "====> Epoch: 49 Average loss: 336.9292\n",
            "====> Epoch: 50 Average loss: 333.6550\n",
            "====> Epoch: 51 Average loss: 330.9668\n",
            "====> Epoch: 52 Average loss: 327.8646\n",
            "====> Epoch: 53 Average loss: 325.2639\n",
            "====> Epoch: 54 Average loss: 322.6263\n",
            "====> Epoch: 55 Average loss: 319.9720\n",
            "====> Epoch: 56 Average loss: 318.9389\n",
            "====> Epoch: 57 Average loss: 316.2556\n",
            "====> Epoch: 58 Average loss: 313.1569\n",
            "====> Epoch: 59 Average loss: 310.4747\n",
            "====> Epoch: 60 Average loss: 307.6227\n",
            "====> Epoch: 61 Average loss: 305.5693\n",
            "====> Epoch: 62 Average loss: 303.3312\n",
            "====> Epoch: 63 Average loss: 301.6780\n",
            "====> Epoch: 64 Average loss: 300.0799\n",
            "====> Epoch: 65 Average loss: 297.4201\n",
            "====> Epoch: 66 Average loss: 295.5405\n",
            "====> Epoch: 67 Average loss: 293.4636\n",
            "====> Epoch: 68 Average loss: 291.9194\n",
            "====> Epoch: 69 Average loss: 290.3870\n",
            "====> Epoch: 70 Average loss: 288.7369\n",
            "====> Epoch: 71 Average loss: 287.6528\n",
            "====> Epoch: 72 Average loss: 285.5883\n",
            "====> Epoch: 73 Average loss: 285.3271\n",
            "====> Epoch: 74 Average loss: 283.9073\n",
            "====> Epoch: 75 Average loss: 281.9672\n",
            "====> Epoch: 76 Average loss: 279.8415\n",
            "====> Epoch: 77 Average loss: 278.4471\n",
            "====> Epoch: 78 Average loss: 277.0257\n",
            "====> Epoch: 79 Average loss: 275.8595\n",
            "====> Epoch: 80 Average loss: 274.6499\n",
            "====> Epoch: 81 Average loss: 274.1488\n",
            "====> Epoch: 82 Average loss: 272.1711\n",
            "====> Epoch: 83 Average loss: 271.0618\n",
            "====> Epoch: 84 Average loss: 269.7377\n",
            "====> Epoch: 85 Average loss: 267.9738\n",
            "====> Epoch: 86 Average loss: 267.3125\n",
            "====> Epoch: 87 Average loss: 266.3977\n",
            "====> Epoch: 88 Average loss: 265.4401\n",
            "====> Epoch: 89 Average loss: 264.0783\n",
            "====> Epoch: 90 Average loss: 262.7262\n",
            "====> Epoch: 91 Average loss: 261.7695\n",
            "====> Epoch: 92 Average loss: 260.8782\n",
            "====> Epoch: 93 Average loss: 259.1414\n",
            "====> Epoch: 94 Average loss: 257.8879\n",
            "====> Epoch: 95 Average loss: 256.6547\n",
            "====> Epoch: 96 Average loss: 256.0609\n",
            "====> Epoch: 97 Average loss: 255.3558\n",
            "====> Epoch: 98 Average loss: 253.9559\n",
            "====> Epoch: 99 Average loss: 253.1416\n",
            "====> Epoch: 100 Average loss: 251.2539\n",
            "====> Epoch: 101 Average loss: 250.0384\n",
            "====> Epoch: 102 Average loss: 248.6646\n",
            "====> Epoch: 103 Average loss: 247.4750\n",
            "====> Epoch: 104 Average loss: 246.2895\n",
            "====> Epoch: 105 Average loss: 246.0236\n",
            "====> Epoch: 106 Average loss: 244.6053\n",
            "====> Epoch: 107 Average loss: 243.7212\n",
            "====> Epoch: 108 Average loss: 243.3256\n",
            "====> Epoch: 109 Average loss: 241.6220\n",
            "====> Epoch: 110 Average loss: 239.9396\n",
            "====> Epoch: 111 Average loss: 238.6302\n",
            "====> Epoch: 112 Average loss: 237.0799\n",
            "====> Epoch: 113 Average loss: 236.0953\n",
            "====> Epoch: 114 Average loss: 234.5817\n",
            "====> Epoch: 115 Average loss: 233.5840\n",
            "====> Epoch: 116 Average loss: 232.5469\n",
            "====> Epoch: 117 Average loss: 231.9629\n",
            "====> Epoch: 118 Average loss: 230.7694\n",
            "====> Epoch: 119 Average loss: 229.5340\n",
            "====> Epoch: 120 Average loss: 228.4546\n",
            "====> Epoch: 121 Average loss: 227.5709\n",
            "====> Epoch: 122 Average loss: 226.1753\n",
            "====> Epoch: 123 Average loss: 225.6164\n",
            "====> Epoch: 124 Average loss: 224.0337\n",
            "====> Epoch: 125 Average loss: 223.3706\n",
            "====> Epoch: 126 Average loss: 221.8748\n",
            "====> Epoch: 127 Average loss: 221.7463\n",
            "====> Epoch: 128 Average loss: 220.5505\n",
            "====> Epoch: 129 Average loss: 219.6026\n",
            "====> Epoch: 130 Average loss: 218.6487\n",
            "====> Epoch: 131 Average loss: 217.1949\n",
            "====> Epoch: 132 Average loss: 216.4334\n",
            "====> Epoch: 133 Average loss: 215.6260\n",
            "====> Epoch: 134 Average loss: 214.8520\n",
            "====> Epoch: 135 Average loss: 213.7044\n",
            "====> Epoch: 136 Average loss: 212.7637\n",
            "====> Epoch: 137 Average loss: 211.6553\n",
            "====> Epoch: 138 Average loss: 210.6647\n",
            "====> Epoch: 139 Average loss: 210.1625\n",
            "====> Epoch: 140 Average loss: 209.7369\n",
            "====> Epoch: 141 Average loss: 209.1492\n",
            "====> Epoch: 142 Average loss: 209.4037\n",
            "====> Epoch: 143 Average loss: 207.4836\n",
            "====> Epoch: 144 Average loss: 206.6035\n",
            "====> Epoch: 145 Average loss: 205.8263\n",
            "====> Epoch: 146 Average loss: 204.8768\n",
            "====> Epoch: 147 Average loss: 204.4727\n",
            "====> Epoch: 148 Average loss: 203.6854\n",
            "====> Epoch: 149 Average loss: 203.2024\n",
            "====> Epoch: 150 Average loss: 203.5818\n",
            "====> Epoch: 151 Average loss: 202.5205\n",
            "====> Epoch: 152 Average loss: 201.8586\n",
            "====> Epoch: 153 Average loss: 200.7405\n",
            "====> Epoch: 154 Average loss: 199.4960\n",
            "====> Epoch: 155 Average loss: 198.3219\n",
            "====> Epoch: 156 Average loss: 197.9880\n",
            "====> Epoch: 157 Average loss: 197.6295\n",
            "====> Epoch: 158 Average loss: 196.6249\n",
            "====> Epoch: 159 Average loss: 196.2148\n",
            "====> Epoch: 160 Average loss: 195.6169\n",
            "====> Epoch: 161 Average loss: 194.7156\n",
            "====> Epoch: 162 Average loss: 194.0826\n",
            "====> Epoch: 163 Average loss: 194.0916\n",
            "====> Epoch: 164 Average loss: 193.1490\n",
            "====> Epoch: 165 Average loss: 192.0889\n",
            "====> Epoch: 166 Average loss: 191.7095\n",
            "====> Epoch: 167 Average loss: 191.2304\n",
            "====> Epoch: 168 Average loss: 190.5125\n",
            "====> Epoch: 169 Average loss: 189.5533\n",
            "====> Epoch: 170 Average loss: 189.1471\n",
            "====> Epoch: 171 Average loss: 188.6422\n",
            "====> Epoch: 172 Average loss: 188.3384\n",
            "====> Epoch: 173 Average loss: 187.5686\n",
            "====> Epoch: 174 Average loss: 187.1292\n",
            "====> Epoch: 175 Average loss: 187.0134\n",
            "====> Epoch: 176 Average loss: 186.1996\n",
            "====> Epoch: 177 Average loss: 185.4734\n",
            "====> Epoch: 178 Average loss: 184.6460\n",
            "====> Epoch: 179 Average loss: 185.1930\n",
            "====> Epoch: 180 Average loss: 184.5232\n",
            "====> Epoch: 181 Average loss: 183.7280\n",
            "====> Epoch: 182 Average loss: 182.7440\n",
            "====> Epoch: 183 Average loss: 181.6459\n",
            "====> Epoch: 184 Average loss: 181.6806\n",
            "====> Epoch: 185 Average loss: 181.0897\n",
            "====> Epoch: 186 Average loss: 180.5413\n",
            "====> Epoch: 187 Average loss: 180.6264\n",
            "====> Epoch: 188 Average loss: 179.8787\n",
            "====> Epoch: 189 Average loss: 179.3505\n",
            "====> Epoch: 190 Average loss: 178.6636\n",
            "====> Epoch: 191 Average loss: 178.1409\n",
            "====> Epoch: 192 Average loss: 177.5702\n",
            "====> Epoch: 193 Average loss: 176.6490\n",
            "====> Epoch: 194 Average loss: 176.3234\n",
            "====> Epoch: 195 Average loss: 176.6154\n",
            "====> Epoch: 196 Average loss: 176.0346\n",
            "====> Epoch: 197 Average loss: 175.2662\n",
            "====> Epoch: 198 Average loss: 174.3104\n",
            "====> Epoch: 199 Average loss: 173.5757\n",
            "====> Epoch: 200 Average loss: 173.2230\n",
            "====> Epoch: 201 Average loss: 172.9819\n",
            "====> Epoch: 202 Average loss: 172.3905\n",
            "====> Epoch: 203 Average loss: 172.1766\n",
            "====> Epoch: 204 Average loss: 171.4995\n",
            "====> Epoch: 205 Average loss: 172.1737\n",
            "====> Epoch: 206 Average loss: 171.1819\n",
            "====> Epoch: 207 Average loss: 170.5022\n",
            "====> Epoch: 208 Average loss: 169.8475\n",
            "====> Epoch: 209 Average loss: 168.9903\n",
            "====> Epoch: 210 Average loss: 168.6716\n",
            "====> Epoch: 211 Average loss: 168.2874\n",
            "====> Epoch: 212 Average loss: 167.8855\n",
            "====> Epoch: 213 Average loss: 167.1734\n",
            "====> Epoch: 214 Average loss: 167.3829\n",
            "====> Epoch: 215 Average loss: 168.7692\n",
            "====> Epoch: 216 Average loss: 166.9804\n",
            "====> Epoch: 217 Average loss: 166.1275\n",
            "====> Epoch: 218 Average loss: 165.8508\n",
            "====> Epoch: 219 Average loss: 165.1478\n",
            "====> Epoch: 220 Average loss: 164.1617\n",
            "====> Epoch: 221 Average loss: 164.1846\n",
            "====> Epoch: 222 Average loss: 163.6106\n",
            "====> Epoch: 223 Average loss: 163.8076\n",
            "====> Epoch: 224 Average loss: 162.7237\n",
            "====> Epoch: 225 Average loss: 161.9936\n",
            "====> Epoch: 226 Average loss: 161.8098\n",
            "====> Epoch: 227 Average loss: 161.1424\n",
            "====> Epoch: 228 Average loss: 160.9678\n",
            "====> Epoch: 229 Average loss: 160.9621\n",
            "====> Epoch: 230 Average loss: 159.9617\n",
            "====> Epoch: 231 Average loss: 160.7079\n",
            "====> Epoch: 232 Average loss: 159.8236\n",
            "====> Epoch: 233 Average loss: 159.1561\n",
            "====> Epoch: 234 Average loss: 158.3383\n",
            "====> Epoch: 235 Average loss: 158.8376\n",
            "====> Epoch: 236 Average loss: 157.9883\n",
            "====> Epoch: 237 Average loss: 157.5037\n",
            "====> Epoch: 238 Average loss: 157.0588\n",
            "====> Epoch: 239 Average loss: 156.6107\n",
            "====> Epoch: 240 Average loss: 156.4694\n",
            "====> Epoch: 241 Average loss: 156.1758\n",
            "====> Epoch: 242 Average loss: 155.5900\n",
            "====> Epoch: 243 Average loss: 155.6666\n",
            "====> Epoch: 244 Average loss: 155.9717\n",
            "====> Epoch: 245 Average loss: 156.0341\n",
            "====> Epoch: 246 Average loss: 155.7802\n",
            "====> Epoch: 247 Average loss: 157.5387\n",
            "====> Epoch: 248 Average loss: 156.7570\n",
            "====> Epoch: 249 Average loss: 155.7229\n",
            "====> Epoch: 250 Average loss: 154.1996\n",
            "====> Epoch: 251 Average loss: 153.6300\n",
            "====> Epoch: 252 Average loss: 153.7477\n",
            "====> Epoch: 253 Average loss: 152.9586\n",
            "====> Epoch: 254 Average loss: 152.3422\n",
            "====> Epoch: 255 Average loss: 152.5586\n",
            "====> Epoch: 256 Average loss: 151.2441\n",
            "====> Epoch: 257 Average loss: 151.6856\n",
            "====> Epoch: 258 Average loss: 151.6124\n",
            "====> Epoch: 259 Average loss: 150.6636\n",
            "====> Epoch: 260 Average loss: 150.6960\n",
            "====> Epoch: 261 Average loss: 149.9467\n",
            "====> Epoch: 262 Average loss: 149.5091\n",
            "====> Epoch: 263 Average loss: 149.6093\n",
            "====> Epoch: 264 Average loss: 149.3823\n",
            "====> Epoch: 265 Average loss: 148.8256\n",
            "====> Epoch: 266 Average loss: 148.8470\n",
            "====> Epoch: 267 Average loss: 148.6773\n",
            "====> Epoch: 268 Average loss: 148.2299\n",
            "====> Epoch: 269 Average loss: 148.8165\n",
            "====> Epoch: 270 Average loss: 147.8420\n",
            "====> Epoch: 271 Average loss: 147.0896\n",
            "====> Epoch: 272 Average loss: 146.2505\n",
            "====> Epoch: 273 Average loss: 145.6149\n",
            "====> Epoch: 274 Average loss: 146.0838\n",
            "====> Epoch: 275 Average loss: 145.4110\n",
            "====> Epoch: 276 Average loss: 145.4376\n",
            "====> Epoch: 277 Average loss: 145.1527\n",
            "====> Epoch: 278 Average loss: 145.2411\n",
            "====> Epoch: 279 Average loss: 144.8475\n",
            "====> Epoch: 280 Average loss: 144.9562\n",
            "====> Epoch: 281 Average loss: 144.3902\n",
            "====> Epoch: 282 Average loss: 144.0843\n",
            "====> Epoch: 283 Average loss: 144.7435\n",
            "====> Epoch: 284 Average loss: 143.9260\n",
            "====> Epoch: 285 Average loss: 143.7826\n",
            "====> Epoch: 286 Average loss: 143.0528\n",
            "====> Epoch: 287 Average loss: 142.8820\n",
            "====> Epoch: 288 Average loss: 142.5333\n",
            "====> Epoch: 289 Average loss: 144.8981\n",
            "====> Epoch: 290 Average loss: 143.9689\n",
            "====> Epoch: 291 Average loss: 143.0946\n",
            "====> Epoch: 292 Average loss: 142.4791\n",
            "====> Epoch: 293 Average loss: 142.6021\n",
            "====> Epoch: 294 Average loss: 141.7736\n",
            "====> Epoch: 295 Average loss: 141.1515\n",
            "====> Epoch: 296 Average loss: 140.3929\n",
            "====> Epoch: 297 Average loss: 140.1372\n",
            "====> Epoch: 298 Average loss: 139.8803\n",
            "====> Epoch: 299 Average loss: 139.8205\n",
            "====> Epoch: 300 Average loss: 139.4327\n",
            "====> Epoch: 301 Average loss: 139.3154\n",
            "====> Epoch: 302 Average loss: 139.0365\n",
            "====> Epoch: 303 Average loss: 138.6488\n",
            "====> Epoch: 304 Average loss: 138.4167\n",
            "====> Epoch: 305 Average loss: 138.5236\n",
            "====> Epoch: 306 Average loss: 138.1639\n",
            "====> Epoch: 307 Average loss: 137.9653\n",
            "====> Epoch: 308 Average loss: 137.8562\n",
            "====> Epoch: 309 Average loss: 137.5964\n",
            "====> Epoch: 310 Average loss: 137.2522\n",
            "====> Epoch: 311 Average loss: 136.7025\n",
            "====> Epoch: 312 Average loss: 137.2515\n",
            "====> Epoch: 313 Average loss: 136.8014\n",
            "====> Epoch: 314 Average loss: 136.0714\n",
            "====> Epoch: 315 Average loss: 136.4742\n",
            "====> Epoch: 316 Average loss: 136.1555\n",
            "====> Epoch: 317 Average loss: 136.1012\n",
            "====> Epoch: 318 Average loss: 136.7534\n",
            "====> Epoch: 319 Average loss: 136.7407\n",
            "====> Epoch: 320 Average loss: 135.8065\n",
            "====> Epoch: 321 Average loss: 135.4458\n",
            "====> Epoch: 322 Average loss: 135.3162\n",
            "====> Epoch: 323 Average loss: 135.3988\n",
            "====> Epoch: 324 Average loss: 136.1264\n",
            "====> Epoch: 325 Average loss: 135.9312\n",
            "====> Epoch: 326 Average loss: 135.9843\n",
            "====> Epoch: 327 Average loss: 137.6535\n",
            "====> Epoch: 328 Average loss: 135.8532\n",
            "====> Epoch: 329 Average loss: 134.2092\n",
            "====> Epoch: 330 Average loss: 133.5393\n",
            "====> Epoch: 331 Average loss: 133.0637\n",
            "====> Epoch: 332 Average loss: 132.4990\n",
            "====> Epoch: 333 Average loss: 133.0812\n",
            "====> Epoch: 334 Average loss: 132.9201\n",
            "====> Epoch: 335 Average loss: 132.6226\n",
            "====> Epoch: 336 Average loss: 132.6600\n",
            "====> Epoch: 337 Average loss: 131.9027\n",
            "====> Epoch: 338 Average loss: 131.2694\n",
            "====> Epoch: 339 Average loss: 130.7808\n",
            "====> Epoch: 340 Average loss: 130.6170\n",
            "====> Epoch: 341 Average loss: 130.4843\n",
            "====> Epoch: 342 Average loss: 130.6541\n",
            "====> Epoch: 343 Average loss: 130.1735\n",
            "====> Epoch: 344 Average loss: 130.4991\n",
            "====> Epoch: 345 Average loss: 131.3327\n",
            "====> Epoch: 346 Average loss: 132.4699\n",
            "====> Epoch: 347 Average loss: 130.4080\n",
            "====> Epoch: 348 Average loss: 129.3748\n",
            "====> Epoch: 349 Average loss: 129.0612\n",
            "====> Epoch: 350 Average loss: 128.7676\n",
            "====> Epoch: 351 Average loss: 128.6594\n",
            "====> Epoch: 352 Average loss: 128.3251\n",
            "====> Epoch: 353 Average loss: 128.0424\n",
            "====> Epoch: 354 Average loss: 128.2348\n",
            "====> Epoch: 355 Average loss: 127.7477\n",
            "====> Epoch: 356 Average loss: 127.5534\n",
            "====> Epoch: 357 Average loss: 127.5464\n",
            "====> Epoch: 358 Average loss: 127.3947\n",
            "====> Epoch: 359 Average loss: 126.8534\n",
            "====> Epoch: 360 Average loss: 128.6863\n",
            "====> Epoch: 361 Average loss: 127.3713\n",
            "====> Epoch: 362 Average loss: 126.8560\n",
            "====> Epoch: 363 Average loss: 128.0611\n",
            "====> Epoch: 364 Average loss: 126.6903\n",
            "====> Epoch: 365 Average loss: 126.1640\n",
            "====> Epoch: 366 Average loss: 126.3262\n",
            "====> Epoch: 367 Average loss: 125.4795\n",
            "====> Epoch: 368 Average loss: 124.4691\n",
            "====> Epoch: 369 Average loss: 124.9395\n",
            "====> Epoch: 370 Average loss: 124.7862\n",
            "====> Epoch: 371 Average loss: 124.5575\n",
            "====> Epoch: 372 Average loss: 124.1643\n",
            "====> Epoch: 373 Average loss: 124.2770\n",
            "====> Epoch: 374 Average loss: 124.0199\n",
            "====> Epoch: 375 Average loss: 123.9581\n",
            "====> Epoch: 376 Average loss: 123.6419\n",
            "====> Epoch: 377 Average loss: 124.7541\n",
            "====> Epoch: 378 Average loss: 123.7294\n",
            "====> Epoch: 379 Average loss: 122.9289\n",
            "====> Epoch: 380 Average loss: 122.7210\n",
            "====> Epoch: 381 Average loss: 122.6930\n",
            "====> Epoch: 382 Average loss: 122.3507\n",
            "====> Epoch: 383 Average loss: 122.0447\n",
            "====> Epoch: 384 Average loss: 121.7595\n",
            "====> Epoch: 385 Average loss: 121.7619\n",
            "====> Epoch: 386 Average loss: 121.6564\n",
            "====> Epoch: 387 Average loss: 121.3170\n",
            "====> Epoch: 388 Average loss: 121.3155\n",
            "====> Epoch: 389 Average loss: 120.9493\n",
            "====> Epoch: 390 Average loss: 120.7584\n",
            "====> Epoch: 391 Average loss: 120.0091\n",
            "====> Epoch: 392 Average loss: 120.4980\n",
            "====> Epoch: 393 Average loss: 120.4088\n",
            "====> Epoch: 394 Average loss: 120.3278\n",
            "====> Epoch: 395 Average loss: 119.9444\n",
            "====> Epoch: 396 Average loss: 119.8448\n",
            "====> Epoch: 397 Average loss: 119.8998\n",
            "====> Epoch: 398 Average loss: 119.5779\n",
            "====> Epoch: 399 Average loss: 119.3572\n",
            "====> Epoch: 400 Average loss: 120.6916\n",
            "====> Epoch: 401 Average loss: 121.1508\n",
            "====> Epoch: 402 Average loss: 119.7968\n",
            "====> Epoch: 403 Average loss: 120.1192\n",
            "====> Epoch: 404 Average loss: 121.9129\n",
            "====> Epoch: 405 Average loss: 119.2550\n",
            "====> Epoch: 406 Average loss: 119.5676\n",
            "====> Epoch: 407 Average loss: 119.0920\n",
            "====> Epoch: 408 Average loss: 118.5373\n",
            "====> Epoch: 409 Average loss: 118.3926\n",
            "====> Epoch: 410 Average loss: 118.0025\n",
            "====> Epoch: 411 Average loss: 117.6516\n",
            "====> Epoch: 412 Average loss: 117.2989\n",
            "====> Epoch: 413 Average loss: 116.7777\n",
            "====> Epoch: 414 Average loss: 116.8724\n",
            "====> Epoch: 415 Average loss: 116.6377\n",
            "====> Epoch: 416 Average loss: 117.5521\n",
            "====> Epoch: 417 Average loss: 117.7666\n",
            "====> Epoch: 418 Average loss: 116.7159\n",
            "====> Epoch: 419 Average loss: 116.3622\n",
            "====> Epoch: 420 Average loss: 116.6991\n",
            "====> Epoch: 421 Average loss: 115.8378\n",
            "====> Epoch: 422 Average loss: 116.6087\n",
            "====> Epoch: 423 Average loss: 116.9559\n",
            "====> Epoch: 424 Average loss: 116.1522\n",
            "====> Epoch: 425 Average loss: 117.4895\n",
            "====> Epoch: 426 Average loss: 116.5963\n",
            "====> Epoch: 427 Average loss: 115.1453\n",
            "====> Epoch: 428 Average loss: 114.8448\n",
            "====> Epoch: 429 Average loss: 114.7185\n",
            "====> Epoch: 430 Average loss: 114.6936\n",
            "====> Epoch: 431 Average loss: 114.8643\n",
            "====> Epoch: 432 Average loss: 114.9220\n",
            "====> Epoch: 433 Average loss: 114.0702\n",
            "====> Epoch: 434 Average loss: 114.7558\n",
            "====> Epoch: 435 Average loss: 114.5497\n",
            "====> Epoch: 436 Average loss: 113.2936\n",
            "====> Epoch: 437 Average loss: 113.7349\n",
            "====> Epoch: 438 Average loss: 115.2323\n",
            "====> Epoch: 439 Average loss: 115.5342\n",
            "====> Epoch: 440 Average loss: 114.2205\n",
            "====> Epoch: 441 Average loss: 113.7884\n",
            "====> Epoch: 442 Average loss: 112.8460\n",
            "====> Epoch: 443 Average loss: 112.1152\n",
            "====> Epoch: 444 Average loss: 112.1472\n",
            "====> Epoch: 445 Average loss: 111.9984\n",
            "====> Epoch: 446 Average loss: 111.5400\n",
            "====> Epoch: 447 Average loss: 111.7607\n",
            "====> Epoch: 448 Average loss: 111.3498\n",
            "====> Epoch: 449 Average loss: 111.2093\n",
            "====> Epoch: 450 Average loss: 111.2326\n",
            "====> Epoch: 451 Average loss: 111.3426\n",
            "====> Epoch: 452 Average loss: 112.0752\n",
            "====> Epoch: 453 Average loss: 113.5304\n",
            "====> Epoch: 454 Average loss: 111.3378\n",
            "====> Epoch: 455 Average loss: 111.5001\n",
            "====> Epoch: 456 Average loss: 111.6349\n",
            "====> Epoch: 457 Average loss: 110.8862\n",
            "====> Epoch: 458 Average loss: 110.5540\n",
            "====> Epoch: 459 Average loss: 110.4948\n",
            "====> Epoch: 460 Average loss: 111.9053\n",
            "====> Epoch: 461 Average loss: 113.2264\n",
            "====> Epoch: 462 Average loss: 111.9646\n",
            "====> Epoch: 463 Average loss: 114.3725\n",
            "====> Epoch: 464 Average loss: 123.6716\n",
            "====> Epoch: 465 Average loss: 120.1816\n",
            "====> Epoch: 466 Average loss: 138.4891\n",
            "====> Epoch: 467 Average loss: 155.1604\n",
            "====> Epoch: 468 Average loss: 173.9768\n",
            "====> Epoch: 469 Average loss: 180.6521\n",
            "====> Epoch: 470 Average loss: 181.5733\n",
            "====> Epoch: 471 Average loss: 180.4790\n",
            "====> Epoch: 472 Average loss: 183.8244\n",
            "====> Epoch: 473 Average loss: 201.9819\n",
            "====> Epoch: 474 Average loss: 209.0036\n",
            "====> Epoch: 475 Average loss: 211.5615\n",
            "====> Epoch: 476 Average loss: 209.9672\n",
            "====> Epoch: 477 Average loss: 205.8786\n",
            "====> Epoch: 478 Average loss: 200.9035\n",
            "====> Epoch: 479 Average loss: 197.5687\n",
            "====> Epoch: 480 Average loss: 192.3488\n",
            "====> Epoch: 481 Average loss: 190.0343\n",
            "====> Epoch: 482 Average loss: 185.9322\n",
            "====> Epoch: 483 Average loss: 181.7035\n",
            "====> Epoch: 484 Average loss: 179.8631\n",
            "====> Epoch: 485 Average loss: 179.5092\n",
            "====> Epoch: 486 Average loss: 181.1212\n",
            "====> Epoch: 487 Average loss: 180.4755\n",
            "====> Epoch: 488 Average loss: 179.1459\n",
            "====> Epoch: 489 Average loss: 174.7592\n",
            "====> Epoch: 490 Average loss: 171.7759\n",
            "====> Epoch: 491 Average loss: 170.6126\n",
            "====> Epoch: 492 Average loss: 170.1962\n",
            "====> Epoch: 493 Average loss: 166.3735\n",
            "====> Epoch: 494 Average loss: 165.6649\n",
            "====> Epoch: 495 Average loss: 163.7448\n",
            "====> Epoch: 496 Average loss: 165.3653\n",
            "====> Epoch: 497 Average loss: 162.3152\n",
            "====> Epoch: 498 Average loss: 159.7403\n",
            "====> Epoch: 499 Average loss: 157.5726\n",
            "====> Epoch: 500 Average loss: 155.6156\n",
            "====> Epoch: 501 Average loss: 154.1652\n",
            "====> Epoch: 502 Average loss: 152.3247\n",
            "====> Epoch: 503 Average loss: 151.0155\n",
            "====> Epoch: 504 Average loss: 149.6679\n",
            "====> Epoch: 505 Average loss: 148.7246\n",
            "====> Epoch: 506 Average loss: 147.3618\n",
            "====> Epoch: 507 Average loss: 146.3742\n",
            "====> Epoch: 508 Average loss: 145.4658\n",
            "====> Epoch: 509 Average loss: 144.1898\n",
            "====> Epoch: 510 Average loss: 143.1655\n",
            "====> Epoch: 511 Average loss: 142.8575\n",
            "====> Epoch: 512 Average loss: 141.9823\n",
            "====> Epoch: 513 Average loss: 140.8202\n",
            "====> Epoch: 514 Average loss: 139.4662\n",
            "====> Epoch: 515 Average loss: 138.1776\n",
            "====> Epoch: 516 Average loss: 137.6478\n",
            "====> Epoch: 517 Average loss: 135.9857\n",
            "====> Epoch: 518 Average loss: 134.9785\n",
            "====> Epoch: 519 Average loss: 133.7483\n",
            "====> Epoch: 520 Average loss: 133.1950\n",
            "====> Epoch: 521 Average loss: 131.2707\n",
            "====> Epoch: 522 Average loss: 130.9691\n",
            "====> Epoch: 523 Average loss: 129.7734\n",
            "====> Epoch: 524 Average loss: 128.9221\n",
            "====> Epoch: 525 Average loss: 127.8124\n",
            "====> Epoch: 526 Average loss: 126.3076\n",
            "====> Epoch: 527 Average loss: 124.9416\n",
            "====> Epoch: 528 Average loss: 124.2311\n",
            "====> Epoch: 529 Average loss: 122.6213\n",
            "====> Epoch: 530 Average loss: 122.0522\n",
            "====> Epoch: 531 Average loss: 120.8860\n",
            "====> Epoch: 532 Average loss: 120.1997\n",
            "====> Epoch: 533 Average loss: 120.7657\n",
            "====> Epoch: 534 Average loss: 120.0373\n",
            "====> Epoch: 535 Average loss: 119.1328\n",
            "====> Epoch: 536 Average loss: 117.5945\n",
            "====> Epoch: 537 Average loss: 116.3693\n",
            "====> Epoch: 538 Average loss: 115.3067\n",
            "====> Epoch: 539 Average loss: 114.6944\n",
            "====> Epoch: 540 Average loss: 114.0176\n",
            "====> Epoch: 541 Average loss: 113.2186\n",
            "====> Epoch: 542 Average loss: 112.5714\n",
            "====> Epoch: 543 Average loss: 112.1727\n",
            "====> Epoch: 544 Average loss: 111.8379\n",
            "====> Epoch: 545 Average loss: 111.9490\n",
            "====> Epoch: 546 Average loss: 111.3359\n",
            "====> Epoch: 547 Average loss: 111.2806\n",
            "====> Epoch: 548 Average loss: 110.9071\n",
            "====> Epoch: 549 Average loss: 109.9903\n",
            "====> Epoch: 550 Average loss: 109.4330\n",
            "====> Epoch: 551 Average loss: 109.2526\n",
            "====> Epoch: 552 Average loss: 108.9737\n",
            "====> Epoch: 553 Average loss: 108.9908\n",
            "====> Epoch: 554 Average loss: 108.2089\n",
            "====> Epoch: 555 Average loss: 108.9676\n",
            "====> Epoch: 556 Average loss: 110.2250\n",
            "====> Epoch: 557 Average loss: 110.7858\n",
            "====> Epoch: 558 Average loss: 109.5121\n",
            "====> Epoch: 559 Average loss: 108.1697\n",
            "====> Epoch: 560 Average loss: 107.6857\n",
            "====> Epoch: 561 Average loss: 107.1130\n",
            "====> Epoch: 562 Average loss: 107.2426\n",
            "====> Epoch: 563 Average loss: 106.8596\n",
            "====> Epoch: 564 Average loss: 106.5163\n",
            "====> Epoch: 565 Average loss: 106.3594\n",
            "====> Epoch: 566 Average loss: 106.0424\n",
            "====> Epoch: 567 Average loss: 106.7537\n",
            "====> Epoch: 568 Average loss: 141.2431\n",
            "====> Epoch: 569 Average loss: 143.6314\n",
            "====> Epoch: 570 Average loss: 153.3726\n",
            "====> Epoch: 571 Average loss: 153.7346\n",
            "====> Epoch: 572 Average loss: 153.3819\n",
            "====> Epoch: 573 Average loss: 154.0069\n",
            "====> Epoch: 574 Average loss: 156.3982\n",
            "====> Epoch: 575 Average loss: 282.1854\n",
            "====> Epoch: 576 Average loss: 218.8578\n",
            "====> Epoch: 577 Average loss: 288.1629\n",
            "====> Epoch: 578 Average loss: 319.2007\n",
            "====> Epoch: 579 Average loss: 330.0483\n",
            "====> Epoch: 580 Average loss: 328.1107\n",
            "====> Epoch: 581 Average loss: 382.1536\n",
            "====> Epoch: 582 Average loss: 353.7299\n",
            "====> Epoch: 583 Average loss: 363.3866\n",
            "====> Epoch: 584 Average loss: 361.4727\n",
            "====> Epoch: 585 Average loss: 393.5586\n",
            "====> Epoch: 586 Average loss: 364.2077\n",
            "====> Epoch: 587 Average loss: 368.0133\n",
            "====> Epoch: 588 Average loss: 363.9599\n",
            "====> Epoch: 589 Average loss: 357.0725\n",
            "====> Epoch: 590 Average loss: 351.8805\n",
            "====> Epoch: 591 Average loss: 350.1461\n",
            "====> Epoch: 592 Average loss: 349.4725\n",
            "====> Epoch: 593 Average loss: 348.8697\n",
            "====> Epoch: 594 Average loss: 344.6612\n",
            "====> Epoch: 595 Average loss: 339.8923\n",
            "====> Epoch: 596 Average loss: 335.0210\n",
            "====> Epoch: 597 Average loss: 330.8646\n",
            "====> Epoch: 598 Average loss: 326.4417\n",
            "====> Epoch: 599 Average loss: 323.5976\n",
            "====> Epoch: 600 Average loss: 319.7316\n",
            "====> Epoch: 601 Average loss: 316.8198\n",
            "====> Epoch: 602 Average loss: 313.9423\n",
            "====> Epoch: 603 Average loss: 311.2121\n",
            "====> Epoch: 604 Average loss: 310.3700\n",
            "====> Epoch: 605 Average loss: 307.9362\n",
            "====> Epoch: 606 Average loss: 304.9149\n",
            "====> Epoch: 607 Average loss: 302.5245\n",
            "====> Epoch: 608 Average loss: 300.2372\n",
            "====> Epoch: 609 Average loss: 297.8425\n",
            "====> Epoch: 610 Average loss: 296.0932\n",
            "====> Epoch: 611 Average loss: 293.0925\n",
            "====> Epoch: 612 Average loss: 290.0134\n",
            "====> Epoch: 613 Average loss: 286.9923\n",
            "====> Epoch: 614 Average loss: 284.7953\n",
            "====> Epoch: 615 Average loss: 281.4957\n",
            "====> Epoch: 616 Average loss: 278.5437\n",
            "====> Epoch: 617 Average loss: 275.0495\n",
            "====> Epoch: 618 Average loss: 272.2150\n",
            "====> Epoch: 619 Average loss: 268.5150\n",
            "====> Epoch: 620 Average loss: 265.6505\n",
            "====> Epoch: 621 Average loss: 262.0344\n",
            "====> Epoch: 622 Average loss: 258.7884\n",
            "====> Epoch: 623 Average loss: 255.7805\n",
            "====> Epoch: 624 Average loss: 252.0499\n",
            "====> Epoch: 625 Average loss: 249.3052\n",
            "====> Epoch: 626 Average loss: 245.9072\n",
            "====> Epoch: 627 Average loss: 242.9222\n",
            "====> Epoch: 628 Average loss: 239.6110\n",
            "====> Epoch: 629 Average loss: 236.1091\n",
            "====> Epoch: 630 Average loss: 237.5679\n",
            "====> Epoch: 631 Average loss: 238.9233\n",
            "====> Epoch: 632 Average loss: 242.7261\n",
            "====> Epoch: 633 Average loss: 252.0491\n",
            "====> Epoch: 634 Average loss: 251.4965\n",
            "====> Epoch: 635 Average loss: 250.3236\n",
            "====> Epoch: 636 Average loss: 250.3407\n",
            "====> Epoch: 637 Average loss: 244.7996\n",
            "====> Epoch: 638 Average loss: 239.9105\n",
            "====> Epoch: 639 Average loss: 232.8997\n",
            "====> Epoch: 640 Average loss: 227.8309\n",
            "====> Epoch: 641 Average loss: 224.3475\n",
            "====> Epoch: 642 Average loss: 221.0917\n",
            "====> Epoch: 643 Average loss: 218.2567\n",
            "====> Epoch: 644 Average loss: 216.4193\n",
            "====> Epoch: 645 Average loss: 213.7815\n",
            "====> Epoch: 646 Average loss: 211.2901\n",
            "====> Epoch: 647 Average loss: 209.2900\n",
            "====> Epoch: 648 Average loss: 208.8618\n",
            "====> Epoch: 649 Average loss: 208.2636\n",
            "====> Epoch: 650 Average loss: 207.2299\n",
            "====> Epoch: 651 Average loss: 209.0436\n",
            "====> Epoch: 652 Average loss: 209.8657\n",
            "====> Epoch: 653 Average loss: 209.4219\n",
            "====> Epoch: 654 Average loss: 206.9816\n",
            "====> Epoch: 655 Average loss: 203.6730\n",
            "====> Epoch: 656 Average loss: 200.9932\n",
            "====> Epoch: 657 Average loss: 199.3943\n",
            "====> Epoch: 658 Average loss: 198.1488\n",
            "====> Epoch: 659 Average loss: 197.1225\n",
            "====> Epoch: 660 Average loss: 196.7595\n",
            "====> Epoch: 661 Average loss: 195.8135\n",
            "====> Epoch: 662 Average loss: 196.7744\n",
            "====> Epoch: 663 Average loss: 195.8478\n",
            "====> Epoch: 664 Average loss: 193.8312\n",
            "====> Epoch: 665 Average loss: 192.6549\n",
            "====> Epoch: 666 Average loss: 190.6285\n",
            "====> Epoch: 667 Average loss: 188.9079\n",
            "====> Epoch: 668 Average loss: 187.8963\n",
            "====> Epoch: 669 Average loss: 186.1066\n",
            "====> Epoch: 670 Average loss: 185.5360\n",
            "====> Epoch: 671 Average loss: 184.4891\n",
            "====> Epoch: 672 Average loss: 184.9570\n",
            "====> Epoch: 673 Average loss: 186.2708\n",
            "====> Epoch: 674 Average loss: 182.8694\n",
            "====> Epoch: 675 Average loss: 181.7312\n",
            "====> Epoch: 676 Average loss: 180.6751\n",
            "====> Epoch: 677 Average loss: 180.3319\n",
            "====> Epoch: 678 Average loss: 179.2921\n",
            "====> Epoch: 679 Average loss: 178.7447\n",
            "====> Epoch: 680 Average loss: 179.2976\n",
            "====> Epoch: 681 Average loss: 177.6906\n",
            "====> Epoch: 682 Average loss: 176.9699\n",
            "====> Epoch: 683 Average loss: 178.6208\n",
            "====> Epoch: 684 Average loss: 178.4092\n",
            "====> Epoch: 685 Average loss: 176.3706\n",
            "====> Epoch: 686 Average loss: 176.1912\n",
            "====> Epoch: 687 Average loss: 176.2719\n",
            "====> Epoch: 688 Average loss: 174.3776\n",
            "====> Epoch: 689 Average loss: 173.0536\n",
            "====> Epoch: 690 Average loss: 172.4877\n",
            "====> Epoch: 691 Average loss: 171.4982\n",
            "====> Epoch: 692 Average loss: 170.4434\n",
            "====> Epoch: 693 Average loss: 169.8136\n",
            "====> Epoch: 694 Average loss: 169.1092\n",
            "====> Epoch: 695 Average loss: 168.0089\n",
            "====> Epoch: 696 Average loss: 167.5165\n",
            "====> Epoch: 697 Average loss: 166.6718\n",
            "====> Epoch: 698 Average loss: 166.1322\n",
            "====> Epoch: 699 Average loss: 166.1208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGQZ8KZx-DKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
